{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating who made the test (ENEM 2016) just for trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "notas_treino = pd.read_csv('train.csv')\n",
    "notas_teste = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using correlation, it was selected the variables that has 25%, at least, of correlation with 'IN_TREINEIRO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NU_IDADE', 'TP_ANO_CONCLUIU', 'TP_ST_CONCLUSAO', 'IN_TREINEIRO']\n"
     ]
    }
   ],
   "source": [
    "corr1 = notas_treino.corr()[notas_treino.corr()['IN_TREINEIRO']<-0.25]['IN_TREINEIRO']\n",
    "corr2 = notas_treino.corr()[notas_treino.corr()['IN_TREINEIRO']>0.25]['IN_TREINEIRO']\n",
    "f_corr1 = corr1.index.to_list()\n",
    "f_corr2 = corr2.index.to_list()\n",
    "feat_corr = f_corr1 + f_corr2\n",
    "feat_corr_test = feat_corr[0:3]\n",
    "print(feat_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NU_IDADE           int64\n",
       "TP_ANO_CONCLUIU    int64\n",
       "TP_ST_CONCLUSAO    int64\n",
       "IN_TREINEIRO       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notas_treino = notas_treino[feat_corr]\n",
    "df_notas_treino.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NU_IDADE           0\n",
      "TP_ANO_CONCLUIU    0\n",
      "TP_ST_CONCLUSAO    0\n",
      "IN_TREINEIRO       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_notas_treino.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if the target variable is unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11947\n",
       "1     1783\n",
       "Name: IN_TREINEIRO, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notas_treino[\"IN_TREINEIRO\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As we can see, the target variable is unbalanced. Let's use SMOTE technique to balance it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_smote, y_smote = smote.fit_resample(df_notas_treino.iloc[:,:-1], df_notas_treino[\"IN_TREINEIRO\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, the target variable is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11947\n",
       "0    11947\n",
       "Name: IN_TREINEIRO, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_smote.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can divide the data into train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v1 = LogisticRegression()\n",
    "model_v1.fit(X_train, y_train)\n",
    "predict_train_v1 = model_v1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'Logistic Regression',\n",
       " 'Precision': 0.9773109243697479,\n",
       " 'Recall': 0.9935924818453652,\n",
       " 'F1 Score': 0.9853844524465156,\n",
       " 'Acurácia': 0.9855618330194601,\n",
       " 'AUC': 0.9855291595587798}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg_v1 = {'Modelo':'Logistic Regression',\n",
    "               'Precision':precision_score(predict_train_v1, y_test),\n",
    "               'Recall':recall_score(predict_train_v1, y_test),\n",
    "               'F1 Score':f1_score(predict_train_v1, y_test),\n",
    "               'Acurácia':accuracy_score(predict_train_v1, y_test),\n",
    "               'AUC':roc_auc_score(y_test, predict_train_v1)}\n",
    "LogReg_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notas_test = notas_teste[feat_corr_test]\n",
    "predict_teste_v1 = model_v1.predict(df_notas_test)\n",
    "predict_teste_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Logistic Regression, we had a predict accuracy of 99,037%. Maybe we can do better using another tecnique..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second model: AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v2 = AdaBoostClassifier(DecisionTreeClassifier(max_depth=None),\n",
    "                          n_estimators=400)\n",
    "model_v2.fit(X_train, y_train)\n",
    "predict_train_v2 = model_v2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'AdaBoostClassifier',\n",
       " 'Precision': 1.0,\n",
       " 'Recall': 0.9875518672199171,\n",
       " 'F1 Score': 0.9937369519832986,\n",
       " 'Acurácia': 0.9937225360954175,\n",
       " 'AUC': 0.9937473947478116}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaBClas_v1 = {'Modelo':'AdaBoostClassifier',\n",
    "               'Precision':precision_score(predict_train_v2, y_test),\n",
    "               'Recall':recall_score(predict_train_v2, y_test),\n",
    "               'F1 Score':f1_score(predict_train_v2, y_test),\n",
    "               'Acurácia':accuracy_score(predict_train_v2, y_test),\n",
    "               'AUC':roc_auc_score(y_test, predict_train_v2)}\n",
    "AdaBClas_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_teste_v2 = model_v2.predict(df_notas_test)\n",
    "predict_teste_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#98,731"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using AdaBoost Classifier, we had a predict accuracy of 98,731%. This one was a little bit worse than Logistic Regression.\n",
    "### Let's try another on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third model: Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v3 = svm.SVC(kernel = 'linear')\n",
    "model_v3.fit(X_train, y_train)\n",
    "predict_train_v3 = model_v3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'SVM',\n",
       " 'Precision': 0.9773109243697479,\n",
       " 'Recall': 0.9935924818453652,\n",
       " 'F1 Score': 0.9853844524465156,\n",
       " 'Acurácia': 0.9855618330194601,\n",
       " 'AUC': 0.9855291595587798}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_v1 = {'Modelo':'SVM',\n",
    "               'Precision':precision_score(predict_train_v3, y_test),\n",
    "               'Recall':recall_score(predict_train_v3, y_test),\n",
    "               'F1 Score':f1_score(predict_train_v3, y_test),\n",
    "               'Acurácia':accuracy_score(predict_train_v3, y_test),\n",
    "               'AUC':roc_auc_score(y_test, predict_train_v3)}\n",
    "SVM_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_teste_v3 = model_v3.predict(df_notas_test)\n",
    "predict_teste_v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SVM, we had a predict accuracy of 99,038%, better than Logistic Regression.\n",
    "### But I'll play my last card!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth model: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v4 = KNeighborsClassifier(n_neighbors=3)\n",
    "model_v4.fit(X_train, y_train)\n",
    "predict_train_v4 = model_v4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'KNeighborsClassifier',\n",
       " 'Precision': 0.9773109243697479,\n",
       " 'Recall': 1.0,\n",
       " 'F1 Score': 0.9885252868678283,\n",
       " 'Acurácia': 0.9887005649717514,\n",
       " 'AUC': 0.988655462184874}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNNClas_v1 = {'Modelo':'KNeighborsClassifier',\n",
    "               'Precision':precision_score(predict_train_v4, y_test),\n",
    "               'Recall':recall_score(predict_train_v4, y_test),\n",
    "               'F1 Score':f1_score(predict_train_v4, y_test),\n",
    "               'Acurácia':accuracy_score(predict_train_v4, y_test),\n",
    "               'AUC':roc_auc_score(y_test, predict_train_v4)}\n",
    "KNNClas_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_teste_v4 = model_v4.predict(df_notas_test)\n",
    "predict_teste_v4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very impressive!!! Using KNN, we had a predict accuracy of 99,69%!!!\n",
    "### Just save this result in a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = notas_teste\n",
    "answer = answer.iloc[:,:1]\n",
    "answer.insert(1, \"IN_TREINEIRO\", predict_teste_v4, True) \n",
    "answer.to_csv('answer.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
